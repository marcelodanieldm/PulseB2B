# ðŸŽ¯ Motor de IA - GuÃ­a de Inicio RÃ¡pido

## âš¡ Setup en 5 Minutos

### 1. Instalar Dependencias ML

**Windows:**
```powershell
.\scripts\setup_ml.ps1
```

**Linux/Mac:**
```bash
chmod +x scripts/setup_ml.sh
./scripts/setup_ml.sh
```

**Manual:**
```bash
pip install xgboost scikit-learn shap pandas numpy
python scripts/train_model.py
```

---

## ðŸš€ Uso BÃ¡sico

### PredicciÃ³n para Una Empresa

```python
from src.ml_predictor import HiringProbabilityPredictor
from src.feature_engineering import FeatureEngineer
from datetime import datetime, timedelta

# 1. Cargar modelo
predictor = HiringProbabilityPredictor(
    model_path='models/hiring_predictor_xgboost.pkl'
)

# 2. Preparar datos
engineer = FeatureEngineer()
features = engineer.extract_features(
    company_data={
        'id': 'anthropic',
        'name': 'Anthropic',
        'region': 'us',
        'team_size': 150,
        'founded_date': datetime(2021, 1, 1)
    },
    funding_data=[{
        'round_type': 'series-c',
        'amount': 450.0,
        'date': datetime.now() - timedelta(days=60)
    }],
    jobs_data=[
        {'title': 'Senior ML Engineer', 'scraped_at': datetime.now()},
        {'title': 'Research Scientist', 'scraped_at': datetime.now()}
    ],
    linkedin_data={
        'current_headcount': 150,
        'departures': [
            {'seniority': 'senior', 'departure_date': datetime.now() - timedelta(days=10)}
        ]
    }
)

# 3. Predecir
prediction = predictor.predict(features)

print(f"Probability: {prediction['prediction']['probability']}%")
print(f"Reasons:")
for reason in prediction['reasons']:
    print(f"  â€¢ {reason}")
```

**Output:**
```
Probability: 85.2%
Reasons:
  â€¢ ðŸ”¥ Reciente SERIES-C ($450M hace 60 dÃ­as) indica expansiÃ³n inminente
  â€¢ ðŸ“ˆ Velocity de vacantes 2.0x vs. mes anterior con 100% roles tech
  â€¢ ðŸ‡ºðŸ‡¸ Estados Unidos + stage Scale = Hiring continuo (factor 1.15)
```

---

## ðŸ“Š PredicciÃ³n Batch

```python
# Predecir para mÃºltiples empresas
companies = [
    # ... lista de empresas
]

features_list = [
    engineer.extract_features(...) for company in companies
]

predictions = predictor.predict_batch(
    features_list,
    output_file='data/predictions.json'
)

# Generar reporte
report = predictor.generate_prediction_report(
    predictions,
    output_file='data/report.json'
)

print(f"High probability: {report['summary']['high_probability']}")
print(f"Average: {report['summary']['average_probability']}%")
```

---

## ðŸŽ¯ Features Principales

| Feature | DescripciÃ³n | Ejemplo | Impacto |
|---------|-------------|---------|---------|
| `funding_recency` | DÃ­as desde Ãºltimo funding | 60 dÃ­as | ðŸ”¥ Alto |
| `tech_churn` | RotaciÃ³n mensual de devs (%) | 12.3% | ðŸ”¥ Alto |
| `job_post_velocity` | Ratio vacantes mes/mes | 2.5x | ðŸ”¥ Alto |
| `region_factor` | Coeficiente econÃ³mico | 1.15 (US) | âš¡ Medio |

**Features Derivadas (automÃ¡ticas):**
- `is_recent_funding`: Bool (< 180 dÃ­as)
- `has_high_churn`: Bool (> 15%)
- `has_velocity_surge`: Bool (> 2.0x)
- `has_senior_exodus`: Bool (â‰¥ 3 seniors)

---

## ðŸ“ˆ InterpretaciÃ³n de Resultados

### Probabilidades

| Rango | Label | Significado |
|-------|-------|-------------|
| **80-100%** | ðŸ”¥ Alta Probabilidad | ContratarÃ¡n casi seguro en 1-2 meses |
| **65-79%** | âš¡ Alta-Media | Muy probable contrataciÃ³n en 2-3 meses |
| **40-64%** | âš¡ Media | Probable, pero no garantizado |
| **20-39%** | â„ï¸ Baja-Media | Poco probable en 3 meses |
| **0-19%** | â„ï¸ Baja | Muy improbable |

### Confianza

- **Very High**: PredicciÃ³n muy confiable (prob >80% o <20%)
- **High**: PredicciÃ³n confiable (prob >65% o <35%)
- **Medium**: PredicciÃ³n moderadamente confiable
- **Low**: PredicciÃ³n poco confiable (prob ~50%)

---

## ðŸ” Debugging

### Verificar Modelo Entrenado

```python
from pathlib import Path

model_path = Path('models/hiring_predictor_xgboost.pkl')
if not model_path.exists():
    print("âŒ Modelo no encontrado. Ejecuta: python scripts/train_model.py")
else:
    print("âœ… Modelo encontrado")
```

### Ver Features ExtraÃ­das

```python
features = engineer.extract_features(...)

# Ver todas las features
df = engineer.features_to_dataframe(features)
print(df.T)  # Transponer para mejor visualizaciÃ³n

# Ver explicaciones
explanations = engineer.get_feature_importance_explanation(features)
for key, value in explanations.items():
    print(f"{key}: {value['explanation']}")
```

### Feature Importance del Modelo

```python
prediction = predictor.predict(features)

# Ver top features impactantes
for item in prediction['feature_importance'][:5]:
    print(f"{item['feature']}: {item['importance_pct']}%")
```

---

## ðŸ§ª Testing

```bash
# Ejecutar tests
python tests/test_ml_engine.py

# Con pytest
pytest tests/test_ml_engine.py -v

# Con coverage
pytest tests/test_ml_engine.py --cov=src --cov-report=html
```

---

## ðŸ“Š Reentrenar Modelo

### Con Datos Reales

```python
from scripts.train_model import SyntheticDataGenerator
from ml_predictor import HiringProbabilityPredictor

# 1. Preparar datos reales
X = pd.DataFrame([...])  # Features
y = np.array([...])       # Labels (1 = contratÃ³, 0 = no contratÃ³)

# 2. Entrenar
predictor = HiringProbabilityPredictor(model_type='xgboost')
metrics = predictor.train(X, y, test_size=0.2)

print(f"ROC AUC: {metrics['roc_auc']:.3f}")
print(f"Accuracy: {metrics['test_accuracy']:.3f}")
```

### Con Datos SintÃ©ticos (MÃ¡s Muestras)

```python
from scripts.train_model import SyntheticDataGenerator

# Generar mÃ¡s datos
generator = SyntheticDataGenerator(n_samples=5000)  # Default: 2000
X, y = generator.generate_training_data()

# Entrenar
predictor = HiringProbabilityPredictor()
predictor.train(X, y)
```

---

## ðŸ”— IntegraciÃ³n con Pipeline

### Con News Intelligence

```python
from src.main import PulseB2BPipeline

# 1. Ejecutar pipeline de noticias
pipeline = PulseB2BPipeline()
news_results = pipeline.run_full_pipeline()

# 2. Para cada empresa, predecir contrataciÃ³n
predictor = HiringProbabilityPredictor()
engineer = FeatureEngineer()

for company in news_results['companies']:
    features = engineer.extract_features(
        company_data=company,
        jobs_data=get_jobs_from_supabase(company['id']),
        funding_data=company['funding'],
        linkedin_data=get_linkedin_data(company['id'])
    )
    
    prediction = predictor.predict(features)
    
    # Guardar en Supabase
    save_prediction_to_db(company['id'], prediction)
```

### Con Job Scraping (Lambda)

```javascript
// lambda/ml_predictor.js
const { spawn } = require('child_process');

exports.handler = async (event) => {
  const { companyId } = event;
  
  // Llamar Python predictor
  const pythonProcess = spawn('python', [
    'scripts/run_predictions.py',
    '--company-id', companyId
  ]);
  
  // Parse output
  const result = await parsePrediction(pythonProcess);
  
  // Guardar en Supabase
  await supabase.from('hiring_predictions').insert({
    company_id: companyId,
    probability: result.prediction.probability,
    reasons: result.reasons,
    predicted_at: new Date()
  });
  
  // Enviar webhook si alta probabilidad
  if (result.prediction.probability >= 70) {
    await sendSlackNotification(result);
  }
  
  return result;
};
```

---

## ðŸ“š Recursos

### DocumentaciÃ³n
- [ML_ENGINE.md](ML_ENGINE.md) - DocumentaciÃ³n completa
- [EXECUTIVE_SUMMARY.md](EXECUTIVE_SUMMARY.md) - Resumen ejecutivo
- [ARCHITECTURE.md](ARCHITECTURE.md) - Arquitectura del sistema

### Ejemplos
- [examples/ml_prediction_example.py](../examples/ml_prediction_example.py) - Ejemplos prÃ¡cticos

### Scripts
- `scripts/train_model.py` - Entrenar modelo
- `scripts/run_predictions.py` - Ejecutar predicciones
- `scripts/setup_ml.sh` / `.ps1` - Setup automÃ¡tico

---

## â“ FAQ

### Â¿Necesito datos reales para entrenar?

No. El modelo viene pre-entrenado con datos sintÃ©ticos que generan ROC AUC ~0.91. Para producciÃ³n, recomendamos reentrenar con datos reales despuÃ©s de 3-6 meses.

### Â¿QuÃ© tan preciso es el modelo?

Con datos sintÃ©ticos: **87.5% accuracy, 91.2% ROC AUC**. Con datos reales bien etiquetados, esperamos >90% accuracy.

### Â¿Puedo usar solo algunas features?

SÃ­, pero con menor precisiÃ³n. Features mÃ­nimas recomendadas:
- `funding_recency`
- `job_post_velocity`
- `region_factor`

### Â¿CÃ³mo obtengo datos de LinkedIn?

Actualmente el sistema estima churn basado en industria (~1.1% mensual). Para datos reales:
1. LinkedIn Sales Navigator API
2. Scraping con Selenium (ToS risk)
3. Servicios como People Data Labs

### Â¿Funciona para empresas no-tech?

El modelo estÃ¡ optimizado para **startups tech**. Para otros sectores, reentrenar con datos especÃ­ficos.

---

## ðŸ†˜ Problemas Comunes

### Error: "Model not found"
```bash
python scripts/train_model.py
```

### Error: "SHAP not installed"
```bash
pip install shap
# O desactivar: predictor.predict(features, explain=False)
```

### Error: "No module named 'xgboost'"
```bash
pip install xgboost
```

### Predicciones todas similares (~50%)
- Modelo no entrenado correctamente
- Features no variadas (todas empresas similares)
- Reentrenar con mÃ¡s diversidad:
  ```bash
  python scripts/train_model.py  # Genera nuevas muestras
  ```

### Bajo ROC AUC en entrenamiento
- Aumentar `n_estimators`: 200 â†’ 500
- Ajustar `max_depth`: 6 â†’ 8
- Generar mÃ¡s muestras: 2000 â†’ 5000

---

**ðŸš€ Â¡Listo para predecir! Ejecuta:**

```bash
python scripts/run_predictions.py
```

---

*Ãšltima actualizaciÃ³n: Diciembre 2025*
