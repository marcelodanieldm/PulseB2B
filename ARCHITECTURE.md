## ğŸ—ï¸ Arquitectura del Sistema

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        PulseB2B Platform                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  NEWS INTELLIGENCE   â”‚         â”‚    JOB SCRAPING SYSTEM       â”‚
â”‚     (Python)         â”‚         â”‚       (Node.js)              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚                                    â”‚
         â”‚                                    â”‚
    â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”                         â”Œâ”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚ Scrapers â”‚                         â”‚  AWS Lambda    â”‚
    â”‚  - Googleâ”‚                         â”‚  Multi-Region  â”‚
    â”‚  - RSS   â”‚                         â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
    â”‚  - News4kâ”‚                         â”‚  â”‚ US-East  â”‚  â”‚
    â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜                         â”‚  â”‚ EU-West  â”‚  â”‚
         â”‚                                â”‚  â”‚ SA-East  â”‚  â”‚
    â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”                        â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
    â”‚Classifier â”‚                        â””â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â”‚  - Keywords                            â”‚
    â”‚  - BERT    â”‚                      â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚  - Sentimentâ”‚                     â”‚ Playwright  â”‚
    â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜                      â”‚  Stealth    â”‚
         â”‚                               â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
    â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”                     â”‚  â”‚Browser â”‚ â”‚
    â”‚ Financial   â”‚                     â”‚  â”‚Context â”‚ â”‚
    â”‚  Analyzer   â”‚                     â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
    â”‚  - Score    â”‚                     â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â”‚  - Insights â”‚                          â”‚
    â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜                     â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚                               â”‚ Proxy Router â”‚
         â”‚                               â”‚  - Free APIs â”‚
         â”‚                               â”‚  - SmartProxyâ”‚
    â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”                     â”‚  - BrightDataâ”‚
    â”‚   Output    â”‚                     â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â”‚  - JSON     â”‚                          â”‚
    â”‚  - Markdown â”‚                     â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚  - Reports  â”‚                     â”‚  Watchlist    â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                     â”‚   Manager     â”‚
                                        â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                             â”‚
                                        â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                                        â”‚   Supabase    â”‚
                                        â”‚  PostgreSQL   â”‚
                                        â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
                                        â”‚  â”‚watchlist â”‚ â”‚
                                        â”‚  â”‚jobs      â”‚ â”‚
                                        â”‚  â”‚logs      â”‚ â”‚
                                        â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
                                        â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                             â”‚
                                        â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                                        â”‚   Webhooks    â”‚
                                        â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
                                        â”‚  â”‚ Slack    â”‚ â”‚
                                        â”‚  â”‚ Discord  â”‚ â”‚
                                        â”‚  â”‚ Telegram â”‚ â”‚
                                        â”‚  â”‚ Email    â”‚ â”‚
                                        â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
                                        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Flujo de Datos

#### News Pipeline:
1. **Scraping** â†’ Obtiene artÃ­culos de mÃºltiples fuentes
2. **Classification** â†’ Categoriza por tipo de evento + sentimiento
3. **Analysis** â†’ Calcula Financial Health Score
4. **Output** â†’ Genera reportes consolidados

#### Job Scraping:
1. **Orchestrator** â†’ Distribuye empresas por regiÃ³n
2. **Lambda Functions** â†’ Ejecutan scraping en paralelo
3. **Playwright** â†’ Navega sitios con evasiÃ³n de detecciÃ³n
4. **Proxy Rotation** â†’ Evita bloqueos geogrÃ¡ficos
5. **Supabase** â†’ Persiste vacantes y detecta nuevas
6. **Webhooks** â†’ Notifica en tiempo real

### Costos Estimados (Free Tier)

| Servicio | Free Tier | Costo despuÃ©s |
|----------|-----------|---------------|
| **AWS Lambda** | 1M requests/mes | $0.20 por 1M requests |
| **Supabase** | 500MB DB, 1GB storage | $25/mes Pro |
| **Proxies Free** | Ilimitado | N/A |
| **SmartProxy** | N/A | $75/mes (5GB) |
| **BrightData** | N/A | $500/mes (20GB) |

**Total Free Tier:** $0/mes para ~10,000 scrapers/mes âœ…

## ğŸ“Š Salidas

### News Pipeline

El pipeline genera varios archivos en el directorio `data/`:

#### 1. `raw_articles_YYYYMMDD_HHMMSS.json`
ArtÃ­culos sin procesar con metadata completa.

#### 2. `classified_articles_YYYYMMDD_HHMMSS.json`
ArtÃ­culos clasificados con:
- CategorÃ­a principal y score
- AnÃ¡lisis de sentimiento
- Empresas mencionadas

#### 3. `company_insights_YYYYMMDD_HHMMSS.json`
Insights agregados por empresa:
```json
{
  "Anthropic": {
    "articles": [...],
    "categories": {"Funding": 3, "Expansion": 1},
    "avg_sentiment": {
      "positive": 0.78,
      "negative": 0.22,
      "overall": "positive"
    }
  }
}
```

#### 4. `financial_scores_YYYYMMDD_HHMMSS.json`
Scores financieros detallados:
```json
{
  "company": "Anthropic",
  "health_score": {
    "overall_score": 82.5,
    "health_status": "excellent",
    "components": {...},
    "metrics": {
      "total_funding": 1154.0,
      "team_size": 150,
      "estimated_burn_rate": 1.5,
      "estimated_runway_months": 24.3
    },
    "insights": [
      "âœ“ Financiamiento muy reciente (3.2 meses).",
      "âœ“ Salud financiera sÃ³lida en general."
    ]
  }
}
```

#### 5. `report_YYYYMMDD_HHMMSS.md`
Reporte consolidado en Markdown con:
- Resumen ejecutivo
- DistribuciÃ³n por categorÃ­a
- Top empresas por menciones
- Financial Health Scores
- ArtÃ­culos destacados

### Job Scraping System

Los datos se persisten en **Supabase** con acceso en tiempo real:

#### Tablas Principales:

**`watchlist`** - Empresas monitoreadas
```sql
id | name | careers_url | scraper_type | region | priority | active
```

**`jobs`** - Vacantes detectadas
```sql
id | company_id | title | link | location | department | scraped_at
```

**`notifications`** - Historial de webhooks
```sql
id | company_id | job_count | channels | sent_at | status
```

**`scrape_logs`** - Logs de ejecuciÃ³n
```sql
id | company_id | region | proxy_used | jobs_found | success | scraped_at
```

#### Consultas Ãštiles:

```sql
-- Jobs recientes (Ãºltimos 7 dÃ­as)
SELECT * FROM recent_jobs LIMIT 50;

-- EstadÃ­sticas por empresa
SELECT * FROM company_stats;

-- BÃºsqueda full-text
SELECT * FROM search_jobs('machine learning');

-- Empresas que necesitan scraping
SELECT * FROM get_companies_needing_scrape(24);
```

## ğŸ”§ ConfiguraciÃ³n Avanzada

### Agregar Fuentes RSS Personalizadas

```python
from news_scraper import RSSFeedSource

# En tu cÃ³digo
monitor.add_source(RSSFeedSource(
    "Mi Fuente",
    "https://mifuente.com/rss"
))
```

### Personalizar Palabras Clave

Edita las categorÃ­as en [src/news_classifier.py](src/news_classifier.py):

```python
self.categories = {
    'Mi Categoria': {
        'keywords': ['palabra1', 'palabra2'],
        'weight': 1.2
    }
}
```

### Ajustar Pesos del Financial Health Score

En [config/config.yaml](config/config.yaml):

```yaml
financial_health:
  weights:
    funding_recency: 0.30  # Aumentar importancia
    funding_amount: 0.15
    # ...
```

### Configurar Scraper Personalizado para Empresa

```javascript
// En Supabase o via API
await watchlistManager.addCompany({
  name: 'CustomCompany',
  careers_url: 'https://company.com/jobs',
  scraper_type: 'custom',
  job_selector: '.job-card', // Selector CSS personalizado
  region: 'us',
  priority: 8
});
```

### Configurar Proxies Profesionales

#### SmartProxy

```bash
# En .env
PROXY_MODE=smartproxy
SMARTPROXY_USERNAME=user-spXXXXXX
SMARTPROXY_PASSWORD=your-password
```

#### BrightData

```bash
# En .env
PROXY_MODE=brightdata
BRIGHTDATA_USERNAME=brd-customer-xxx
BRIGHTDATA_PASSWORD=your-password
```

### Ajustar Frecuencia de Scraping

Edita [template.yaml](template.yaml):

```yaml
Events:
  ScheduledEvent:
    Type: Schedule
    Properties:
      Schedule: rate(2 hours)  # Cambiar a 2 horas
      Enabled: true
```

Redeploy:
```bash
sam deploy
```
